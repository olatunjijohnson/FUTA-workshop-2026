% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
  aspectratio=169,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{section title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{subsection title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\usetheme[]{default}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{graphicx}
\usepackage{xcolor}

% UoM-style purple
\definecolor{uomPurple}{HTML}{6A1B9A}
\setbeamercolor{structure}{fg=uomPurple}
\setbeamercolor{title}{fg=uomPurple}
\setbeamercolor{frametitle}{fg=uomPurple}

% Define the logo (file must exist)
\newcommand{\uomlogo}{\includegraphics[height=1cm]{images2/uom_logo.pdf}}

% Force logo into the top-right of every slide
\setbeamertemplate{headline}{%
  \leavevmode%
  \hbox{%
    \begin{beamercolorbox}[wd=\paperwidth,ht=1.2cm]{}%
      \hfill\uomlogo\hspace{0.5cm}%
    \end{beamercolorbox}%
  }%
}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Day 1 -- Spatial \& Spatio-temporal Modelling},
  pdfauthor={Olatunji Johnson},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}


\title{Day 1 -- Spatial \& Spatio-temporal Modelling}
\author{Olatunji Johnson}
\date{}

\begin{document}
\frame{\titlepage}


\section{Introduction}\label{introduction}

\begin{frame}{About me}
\phantomsection\label{about-me}
\begin{itemize}
\tightlist
\item
  Completed a Bachelor's degree in Statistics at FUTA
\item
  Master's in Mathamatical Sciences at AIMS-Tanzania
\item
  PhD in Statistics and Epidemiology at University of Lancaster
\item
  Postdoc at University of Manchester
\item
  Lecturer in Statistics at the University of Manchester
\end{itemize}
\end{frame}

\begin{frame}{Overview of the 3 days}
\phantomsection\label{overview-of-the-3-days}
\begin{itemize}
\tightlist
\item
  Spatial and spatio-temporal analysis (different likelihoods)
\item
  Joint modelling of multiple malaria processes
\item
  Non-stationary spatial processes
\item
  Hybrid machine learning + geostatistical models
\end{itemize}
\end{frame}

\begin{frame}{Linear Regression}
\phantomsection\label{linear-regression}
\begin{itemize}
\tightlist
\item
  Goal: Model a continuous response variable as a linear function of
  predictors.
\item
  Model \(Y = X \beta + \epsilon\), where
  \(\epsilon \sim N(0, \sigma^2)\)
\item
  Key Assumption

  \begin{itemize}
  \tightlist
  \item
    Linearity
  \item
    Independence
  \item
    Homoscedasticity (constant variance)
  \item
    Normality of errors
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Generalized Linear Models (GLMs)}
\phantomsection\label{generalized-linear-models-glms}
\begin{itemize}
\tightlist
\item
  Extension of linear models to handle non-normal response
  distributions.
\item
  Three components:

  \begin{itemize}
  \tightlist
  \item
    Random component: Distribution from the exponential family (e.g.,
    Binomial, Poisson).
  \item
    Systematic component: Linear predictor \(\eta = X\beta\).
  \item
    Link function: Relates \(E(Y)\) to \(\eta\).
  \end{itemize}
\item
  Examples:

  \begin{itemize}
  \tightlist
  \item
    Logistic regression for binary outcomes --
    {\texttt{logit\ link\ function}}
  \item
    Poisson regression for count data -- {\texttt{log\ link\ function}}
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Why Spatial Statistics?}
\phantomsection\label{why-spatial-statistics}
\begin{itemize}
\item
  \textbf{Spatial Dependence:}\\
  Observations collected at nearby locations are often more similar than
  those farther apart.
\item
  \textbf{Ignoring Spatial Structure:}

  \begin{itemize}
  \tightlist
  \item
    Leads to biased parameter estimates.
  \item
    Underestimates uncertainty.
  \item
    Misses important spatial patterns.
  \end{itemize}
\item
  \textbf{Applications:}

  \begin{itemize}
  \tightlist
  \item
    Disease mapping\\
  \item
    Environmental monitoring\\
  \item
    Agricultural field trials
  \end{itemize}
\item
  \textbf{Goal:}\\
  Account for spatial correlation to improve prediction and inference.
\end{itemize}
\end{frame}

\section{Spatial Analysis}\label{spatial-analysis}

\begin{frame}{Spatial Statistics}
\phantomsection\label{spatial-statistics}
\begin{columns}[T]
\begin{column}{0.48\linewidth}
\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images2/cressie2.png}}

}

\caption{Cressie 1991}

\end{figure}%
\end{column}

\begin{column}{0.48\linewidth}
\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images2/gelfand.png}}

}

\caption{Gelfand 2010}

\end{figure}%
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Classification of spatial statistics}
\phantomsection\label{classification-of-spatial-statistics}
Cressie's book classifies spatial statistics according to \textbf{data
format}:

\begin{enumerate}
\tightlist
\item
  Geostatistical data\\
\item
  Lattice data\\
\item
  Point patterns
\end{enumerate}

Gelfand's book classifies spatial statistics according to
\textbf{spatial variation}:

\begin{enumerate}
\tightlist
\item
  Discrete spatial variation: Gaussian Markov Random Field (GMRF)\\
\item
  Continuous spatial variation: Gaussian Random Field (GMRF)
\end{enumerate}
\end{frame}

\begin{frame}{Geostatistical data: River blindness in Cameroon}
\phantomsection\label{geostatistical-data-river-blindness-in-cameroon}
\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images2/check.png}}

}

\caption{Geostatistical data: River blindness in Cameroon}

\end{figure}%
\end{frame}

\begin{frame}{Lattice Data: COPD emergency admission}
\phantomsection\label{lattice-data-copd-emergency-admission}
\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images2/incidence_rate.png}}

}

\caption{Lattice data: COPD emergency admission}

\end{figure}%
\end{frame}

\begin{frame}{Point pattern: Primary biliary cirrhosis data}
\phantomsection\label{point-pattern-primary-biliary-cirrhosis-data}
\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images2/point_map2.png}}

}

\caption{Point pattern: Primary biliary cirrhosis data}

\end{figure}%
\end{frame}

\section{Model-based Geostatistics}\label{model-based-geostatistics}

\begin{frame}{Modelling Geostatistical Data -- Model-based
Geostatistics}
\phantomsection\label{modelling-geostatistical-data-model-based-geostatistics}
\begin{itemize}
\tightlist
\item
  The term \textbf{Model-based Geostatistics (MBG)} was coined by Peter
  Diggle in 1998 (Diggle, Tawn, and Moyeed 1998; Diggle and Giorgi
  2019).
\item
  MBG applies general principles of statistical modelling and inference
  to the analysis of geostatistical data.
\item
  It emphasises the use of likelihood-based inference.
\item
  \textbf{{and the use of latent spatial process (Gaussian or stochastic
  process)}}
\end{itemize}
\end{frame}

\begin{frame}{Standard MBG model}
\phantomsection\label{standard-mbg-model}
\[
Y_i = \beta_0 
+ \underbrace{\beta_1 d_1(x_i) + \beta_2 d_2(x_i)}_{\text{explained}}
+ \underbrace{S(x_i) + Z_j}_{\text{unexplained}},
\]

where

\begin{itemize}
\tightlist
\item
  \(\beta_0\), \(\beta_1\), and \(\beta_2\) are regression coefficients;
\item
  \(d_1(x)\) and \(d_2(x)\) denote covariates/predictors at location
  \(x\);
\item
  \(S(x)\) is the stochastic spatial process;
\item
  \(Z_j\) represents measurement error.
\end{itemize}
\end{frame}

\begin{frame}{Modelling \(S(x)\) and \(Z_j\)}
\phantomsection\label{modelling-sx-and-z_j}
\begin{itemize}
\tightlist
\item
  \(Z_i \sim N(0, \tau^2)\)
\item
  We assume that \(S(x)\) is a zero-mean \textbf{{stationary and
  isotropic Gaussian process}}. i.e \(S \sim \text{MVN}(0, \Sigma)\)
\item
  The \((i,j)\)th entry of \(\Sigma\) is \[
  \Sigma_{ij} = \operatorname{Cov}\big(S(x_i), S(x_j)\big) = \sigma^2 \rho(u)
  \]
\item
  \(u = \|x_i - x_j\|\) is the Euclidean distance between locations
  \(x_i\) and \(x_j\)
\item
  \textbf{{How do we choose parametric correlation function
  \(\rho(\cdot)\)?}}
\end{itemize}
\end{frame}

\begin{frame}{The Mat√©rn correlation function}
\phantomsection\label{the-matuxe9rn-correlation-function}
\[
\rho(u; \phi, \kappa)
= \frac{1}{2^{\kappa-1}\Gamma(\kappa)}
\left(\frac{u}{\phi}\right)^\kappa
K_\kappa\!\left(\frac{u}{\phi}\right),
\]

\begin{itemize}
\item
  \(K_\kappa(\cdot)\): modified Bessel function of order \(\kappa\)
\item
  \textbf{{Interpretation}}

  \begin{itemize}
  \tightlist
  \item
    \(\kappa\) determines the smoothness:
    \(\kappa > r \Rightarrow S(x)\) is \(r\) times differentiable
  \item
    \(\phi\) determines the scale of spatial correlation
  \end{itemize}
\item
  \textbf{{Special cases}}

  \begin{itemize}
  \tightlist
  \item
    \(\kappa = 0.5 \Rightarrow \rho(u) = \exp\{-u/\phi\}\)
  \item
    \(\kappa \to \infty \Rightarrow \rho(u) = \exp\{-(u/\phi)^2\}\)
  \end{itemize}
\item
  Often sufficient to choose \(\kappa \in \{0.5, 1.5, 2.5\}\)
\end{itemize}
\end{frame}

\begin{frame}{Mat√©rn correlation function -- \(\kappa\)}
\phantomsection\label{matuxe9rn-correlation-function-kappa}
\[
\rho(u; \phi, \kappa)
= \frac{1}{2^{\kappa-1}\Gamma(\kappa)}
\left(\frac{u}{\phi}\right)^\kappa
K_\kappa\!\left(\frac{u}{\phi}\right),
\]

\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{images2/correlationfuncplot1.pdf}

\textbf{{Exponential correlation function:}}
\(\rho(u; \phi, 0.5) = \exp\{-u/\phi\}\)
\end{frame}

\begin{frame}{The scale of the spatial correlation -- \(\phi\)}
\phantomsection\label{the-scale-of-the-spatial-correlation-phi}
\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{images2/spatial_cor.pdf}
\end{frame}

\begin{frame}{Do we need the process \(S(x)\)?}
\phantomsection\label{do-we-need-the-process-sx}
\begin{itemize}
\item
  Regression residuals\\
  \[
  \hat{r}_i = Y_i - \hat{Y}_i
  \] from a GLM
\item
  Each \(\hat{r}_i\) estimates\\
  \[
  S(x_i) + Z_i
  \]
\end{itemize}
\end{frame}

\begin{frame}{The variogram}
\phantomsection\label{the-variogram}
\begin{columns}[T]
\begin{column}{0.48\linewidth}
\begin{itemize}
\item
  \textbf{Empirical variogram} \[
  \hat{V}(u) = \frac{1}{2|N(u)|}\sum_{(i,j)\in N(u)}(\hat{r}_i-\hat{r}_j)^2
  \]
\item
  where\\
  \[
  N(u)=\{(i,j): \lVert x_i-x_j\rVert=u\}
  \]
\end{itemize}
\end{column}

\begin{column}{0.48\linewidth}
\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{images2/lead1997_vario.pdf}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Confirming existence of spatial correlation}
\phantomsection\label{confirming-existence-of-spatial-correlation}
\begin{columns}[T]
\begin{column}{0.48\linewidth}
\begin{enumerate}
\tightlist
\item
  Randomly permute the (\hat{r}\_i) while holding the locations (x)
  fixed\\
\item
  Compute the empirical variogram using the permuted (\hat{r}\_i)\\
\item
  Repeat steps 1--2 (B) times\\
\item
  Use the resulting (B) variograms to compute \textbf{pointwise 95\%
  tolerance bands} at each distance bin\\
\item
  If the observed variogram lies outside the 95\% band, this indicates
  \textbf{residual spatial correlation}
\end{enumerate}
\end{column}

\begin{column}{0.48\linewidth}
\includegraphics[width=0.75\linewidth,height=\textheight,keepaspectratio]{images2/lead1997_permuted_vario.pdf}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Inference: Maximum likelihood estimation}
\phantomsection\label{inference-maximum-likelihood-estimation}
\begin{itemize}
\item
  \textbf{{Multivariate Gaussian distribution}}\\
  \[
  Y \sim \text{MVN}(D\beta, \sigma^2 R + \tau^2 I)
  \]

  \begin{itemize}
  \tightlist
  \item
    \(D\): matrix of covariates, \([D]_{ik} = d_k(x_i)\)\\
  \item
    \(R\): spatial correlation matrix,\\
    \([R]_{ij} = \rho(u_{ij})\), with \(u_{ij} = \|x_i - x_j\|\)
  \end{itemize}
\item
  \textbf{{Fitting process}}

  \begin{enumerate}
  \tightlist
  \item
    Initialise \(\beta\) (e.g.~using ordinary least squares)
  \item
    Initialise \(\theta\) (e.g.~using the empirical variogram)
  \item
    Maximise \[
    \ell(\theta) = \log\{f(y; \beta, \theta)\},
    \] where \(f(\cdot; \beta, \theta)\) is the multivariate Gaussian
    density
  \end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}{Beyond Gaussian responses}
\phantomsection\label{beyond-gaussian-responses}
So far, we assumed: \[
Y \sim \text{MVN}(D\beta, \sigma^2 R + \tau^2 I)
\]

However, many geostatistical datasets are:

\begin{itemize}
\tightlist
\item
  Binary (presence / absence)
\item
  Counts (number of cases)
\item
  Rates or proportions
\end{itemize}

A \textbf{Gaussian likelihood is no longer appropriate}
\end{frame}

\begin{frame}{Separating data and process models}
\phantomsection\label{separating-data-and-process-models}
Model-based geostatistics distinguishes between:

\begin{itemize}
\item
  \textbf{Observation model (likelihood):} \[
  Y_i \mid \eta_i \sim \pi(y_i \mid \eta_i)
  \]
\item
  \textbf{Latent process model:} \[
  \eta_i = X_i \beta + S(x_i) + Z_i
  \]
\end{itemize}

Key idea:

\begin{itemize}
\tightlist
\item
  Non-Gaussian data
\item
  Gaussian latent structure
\end{itemize}
\end{frame}

\begin{frame}{Common likelihoods in practice}
\phantomsection\label{common-likelihoods-in-practice}
\begin{itemize}
\item
  \textbf{Gaussian} \[
  Y_i \mid \eta_i \sim N(\eta_i, \sigma^2)
  \] Continuous measurements (e.g.~pollution levels)
\item
  \textbf{Binomial} \[
  Y_i \mid \eta_i \sim \text{Binomial}(n_i, p_i),
  \qquad \text{logit}(p_i) = \eta_i
  \] Prevalence survey data
\item
  \textbf{Poisson} \[
  Y_i \mid \eta_i \sim \text{Poisson}(\lambda_i),
  \qquad \log(\lambda_i) = \eta_i
  \] Disease counts, event data
\end{itemize}
\end{frame}

\begin{frame}{Link functions}
\phantomsection\label{link-functions}
The linear predictor enters the likelihood via a link:

\[
g(\mu_i) = \eta_i = X_i\beta + S(x_i) + Z_i
\]

Examples:

\begin{itemize}
\tightlist
\item
  Identity link ‚Üí Gaussian data
\item
  Logit link ‚Üí Binomial data
\item
  Log link ‚Üí Poisson data
\end{itemize}

This gives a \textbf{generalized linear mixed model (GLMM)} structure
\end{frame}

\begin{frame}{Computational challenges}
\phantomsection\label{computational-challenges}
For non-Gaussian likelihoods:

\begin{itemize}
\item
  The marginal likelihood requires: \[
  L(\theta) = \int \pi(y \mid S, \theta)\pi(S \mid \theta)\,dS
  \]
\item
  High-dimensional integral over latent field \(x\)
\item
  No closed-form solution
\end{itemize}

Consequences:

\begin{itemize}
\tightlist
\item
  Maximum likelihood is expensive
\item
  Bayesian inference via MCMC is slow
\end{itemize}
\end{frame}

\begin{frame}{Classical solutions and limitations}
\phantomsection\label{classical-solutions-and-limitations}
\begin{itemize}
\tightlist
\item
  Laplace approximation
\item
  Penalised quasi-likelihood (PQL)
\item
  MCMC-based Bayesian inference
\end{itemize}

Limitations:

\begin{itemize}
\tightlist
\item
  Poor scalability for large spatial fields
\item
  Long runtimes
\item
  Difficult model exploration
\end{itemize}
\end{frame}

\begin{frame}{Key takeaway}
\phantomsection\label{key-takeaway}
We want:

\begin{itemize}
\tightlist
\item
  Flexible likelihoods (Binomial, Poisson, etc.)
\item
  Spatial and spatio-temporal random effects
\item
  Bayesian inference
\item
  Computational efficiency
\end{itemize}

This motivates \textbf{Integrated Nested Laplace Approximation (INLA)}
\end{frame}

\begin{frame}{From likelihoods to INLA}
\phantomsection\label{from-likelihoods-to-inla}
Hierarchical models setup:

\begin{itemize}
\tightlist
\item
  Data likelihood: possibly non-Gaussian
\item
  Latent field: Gaussian with spatial dependence
\item
  Hyperparameters: low-dimensional
\end{itemize}

This class of models is known as \textbf{Latent Gaussian Models}

INLA is designed specifically for this class
\end{frame}

\begin{frame}{Why INLA?}
\phantomsection\label{why-inla}
\begin{itemize}
\tightlist
\item
  Fully Bayesian inference for latent Gaussian models is often
  computationally expensive
\item
  Markov chain Monte Carlo (MCMC):

  \begin{itemize}
  \tightlist
  \item
    Accurate but slow for large spatial datasets
  \item
    Poor scaling with dimension of latent field
  \end{itemize}
\item
  \textbf{INLA} provides:

  \begin{itemize}
  \tightlist
  \item
    Deterministic (non-sampling) approximation
  \item
    Orders-of-magnitude speed-ups
  \item
    Accurate marginal posterior distributions
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Latent Gaussian models}
\phantomsection\label{latent-gaussian-models}
INLA is designed for \textbf{latent Gaussian models (LGMs)}:

\[
y_i \mid \eta_i, \theta \sim \pi(y_i \mid \eta_i, \theta),
\qquad
\eta = A S
\]

where

\begin{itemize}
\tightlist
\item
  \(S \sim \mathcal{N}(0, Q(\theta)^{-1})\) is a latent Gaussian field
\item
  \(A\) is a known design / projection matrix
\item
  \(\theta\) are low-dimensional hyperparameters
\end{itemize}

Examples of \(S\):

\begin{itemize}
\tightlist
\item
  Spatial Gaussian random fields
\item
  Temporal effects
\item
  Random effects and smoothers
\end{itemize}
\end{frame}

\begin{frame}{Key idea: sparsity}
\phantomsection\label{key-idea-sparsity}
\begin{itemize}
\tightlist
\item
  Latent field \(S\) is modelled as a \textbf{Gaussian Markov Random
  Field (GMRF)}
\item
  GMRFs have \textbf{sparse precision matrices} \(Q(\theta)\)
\end{itemize}

Why this matters:

\begin{itemize}
\tightlist
\item
  Sparse matrix algebra is fast
\item
  Enables scalable inference for large spatial problems
\item
  Crucial for INLA's computational efficiency
\end{itemize}
\end{frame}

\begin{frame}{Stage 1: Hyperparameter inference}
\phantomsection\label{stage-1-hyperparameter-inference}
Goal: \[
\pi(\theta \mid y) \propto \frac{\pi(y \mid S, \theta)\pi(S \mid \theta)\pi(\theta)}
{\pi(S \mid y, \theta)}
\]

\begin{itemize}
\tightlist
\item
  INLA uses a \textbf{Laplace approximation} to integrate out \(S\)
\item
  Produces an accurate approximation to: \[
  \pi(\theta \mid y)
  \]
\end{itemize}

Key point:

\begin{itemize}
\tightlist
\item
  \(\theta\) is low-dimensional ‚Üí numerical optimisation is feasible
\end{itemize}
\end{frame}

\begin{frame}{Stage 2: Latent field given \(\theta\)}
\phantomsection\label{stage-2-latent-field-given-theta}
\begin{itemize}
\item
  Conditional on \(\theta\), INLA approximates: \[
  \pi(S \mid \theta, y)
  \]
\item
  Approximation:

  \begin{itemize}
  \tightlist
  \item
    Gaussian
  \item
    Centered at the mode of the conditional posterior
  \item
    Uses local curvature (Hessian)
  \end{itemize}
\end{itemize}

This step exploits:

\begin{itemize}
\tightlist
\item
  Gaussian structure of \(S\)
\item
  Sparse precision matrix
\end{itemize}
\end{frame}

\begin{frame}{Stage 3: Marginal posteriors}
\phantomsection\label{stage-3-marginal-posteriors}
Final goal: \[
\pi(S_i \mid y), \qquad \pi(\theta_j \mid y)
\]

INLA computes: \[
\pi(S_i \mid y)
=
\int \pi(S_i \mid \theta, y)\,\pi(\theta \mid y)\,d\theta
\]

\begin{itemize}
\item
  Integration performed numerically
\item
  Output:

  \begin{itemize}
  \tightlist
  \item
    Marginal posterior means
  \item
    Credible intervals
  \item
    Full marginal densities
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{GRF vs GMRF: concept vs computation}
\phantomsection\label{grf-vs-gmrf-concept-vs-computation}
Lindgren, Rue, and Lindstr√∂m (2011) provides the link between the two.

\begin{itemize}
\tightlist
\item
  \textbf{Gaussian Random Field (GRF):}

  \begin{itemize}
  \tightlist
  \item
    Defined on a continuous spatial domain
  \item
    Used for geostatistical modelling
  \item
    Dense covariance structure
  \end{itemize}
\item
  \textbf{Gaussian Markov Random Field (GMRF):}

  \begin{itemize}
  \tightlist
  \item
    Defined on a finite set of locations
  \item
    Sparse precision matrix
  \item
    Computationally efficient
  \end{itemize}
\end{itemize}

Key point:

üëâ In INLA, a \textbf{GMRF is used as a computational approximation} to
a \textbf{continuous GRF}
\end{frame}

\begin{frame}{Spatial modelling in INLA: SPDE approach}
\phantomsection\label{spatial-modelling-in-inla-spde-approach}
\begin{itemize}
\tightlist
\item
  Continuous Gaussian random fields are represented via:
  \textbf{Stochastic Partial Differential Equations (SPDEs)}
\end{itemize}

Key ideas:

\begin{itemize}
\tightlist
\item
  Start with a Mat√©rn GRF (continuous)
\item
  Approximate it on a triangulated mesh
\item
  Obtain a \textbf{computational GMRF}
\item
  Retain Mat√©rn covariance structure
\end{itemize}

Benefits:

\begin{itemize}
\tightlist
\item
  Sparse precision matrix
\item
  Fast Bayesian inference with INLA
\end{itemize}
\end{frame}

\begin{frame}{Why the SPDE approach?}
\phantomsection\label{why-the-spde-approach}
\begin{itemize}
\item
  In geostatistics, we often model spatial dependence using
  \textbf{Gaussian random fields (GRFs)} with Mat√©rn covariance
\item
  For observations at locations \(x_1, \dots, x_n\):

  \begin{itemize}
  \tightlist
  \item
    Covariance matrix is \textbf{dense}
  \item
    Computational cost is \(\mathcal{O}(n^3)\)
  \end{itemize}
\end{itemize}

This becomes infeasible for large spatial datasets
\end{frame}

\begin{frame}{Gaussian random fields}
\phantomsection\label{gaussian-random-fields}
A spatial Gaussian random field is defined as:

\[
S(x) \sim \text{GRF}(0, C(\cdot))
\]

with covariance function: \[
\text{Cov}\{S(x), S(x')\} = C(\|x - x'\|)
\]

\begin{itemize}
\tightlist
\item
  The Mat√©rn family is widely used
\item
  Defined on a \textbf{continuous spatial domain}
\end{itemize}
\end{frame}

\begin{frame}{From covariance to SPDE}
\phantomsection\label{from-covariance-to-spde}
A key result (Whittle, 1954):

A Mat√©rn GRF is the solution to the SPDE: \[
(\kappa^2 - \Delta)^{\alpha/2} S(x)
= \mathcal{W}(x),
\]

where: - \(\Delta\) is the Laplacian operator - \(\mathcal{W}(x)\) is
Gaussian white noise - Parameters \((\kappa, \alpha)\) control range and
smoothness
\end{frame}

\begin{frame}{Discretising the SPDE}
\phantomsection\label{discretising-the-spde}
\begin{itemize}
\tightlist
\item
  The spatial domain is discretised using a \textbf{triangular mesh}
\item
  The continuous field is approximated as: \[
  S(x) \approx \sum_{k=1}^K w_k \psi_k(x)
  \]
\end{itemize}

where:

\begin{itemize}
\tightlist
\item
  \(\psi_k(x)\) are basis functions
\item
  \(w_k\) are random weights
\end{itemize}

Local support of basis functions ‚áí sparsity
\end{frame}

\begin{frame}{From GRF to GMRF}
\phantomsection\label{from-grf-to-gmrf}
\begin{itemize}
\item
  The SPDE discretisation yields \[
  \mathbf{w} \sim \mathcal{N}(0, Q^{-1})
  \]
\item
  Precision matrix \(Q\) is \textbf{sparse}
\item
  This defines a \textbf{Gaussian Markov Random Field (GMRF)}
\end{itemize}

Key consequence: - Fast computation - Scales to large spatial problems
\end{frame}

\begin{frame}{SPDE approach: summary}
\phantomsection\label{spde-approach-summary}
\begin{itemize}
\tightlist
\item
  Specify a Mat√©rn Gaussian random field
\item
  Use its equivalent SPDE representation
\item
  Approximate the SPDE on a triangulated mesh
\item
  Obtain a sparse GMRF representation
\item
  Perform fast Bayesian inference using INLA
\end{itemize}
\end{frame}

\begin{frame}{When should you use INLA?}
\phantomsection\label{when-should-you-use-inla}
INLA is well suited for:

\begin{itemize}
\tightlist
\item
  Spatial and spatio-temporal models
\item
  Latent Gaussian models
\item
  Large datasets with structured dependence
\end{itemize}

INLA is less suitable for:

\begin{itemize}
\tightlist
\item
  Highly non-Gaussian latent structures
\item
  Very high-dimensional hyperparameter spaces
\item
  Models requiring full joint posterior samples
\end{itemize}
\end{frame}

\begin{frame}[fragile]{\texttt{INLA} and \texttt{inlabru} R packages}
\phantomsection\label{inla-and-inlabru-r-packages}
\textbf{What is \texttt{inlabru}?}

\begin{itemize}
\item
  An R package built on top of \texttt{INLA}
\item
  Designed for spatial and spatio-temporal modelling using\\
  \textbf{Integrated Nested Laplace Approximation (INLA)}
\item
  Provides an intuitive interface for:

  \begin{itemize}
  \tightlist
  \item
    Spatial point process models
  \item
    Geostatistical models
  \end{itemize}
\item
  Install \texttt{INLA}: \url{https://www.r-inla.org/download-install}
\item
  Examples and documentation:
  \url{https://inlabru-org.github.io/inlabru/}
\end{itemize}

\textbf{Key features}

\begin{itemize}
\tightlist
\item
  Formula-based model specification
\item
  Flexible integration with \texttt{sf}, \texttt{sp}, and
  \texttt{raster}
\end{itemize}
\end{frame}

\begin{frame}{References}
\phantomsection\label{references}
\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-diggle2019model}
Diggle, Peter, and Emanuele Giorgi. 2019. \emph{Model-Based
Geostatistics}. CRC Press.

\bibitem[\citeproctext]{ref-diggle1998model}
Diggle, Peter, Jonathan Tawn, and Rana Moyeed. 1998. {``Model-Based
Geostatistics.''} \emph{Journal of the Royal Statistical Society: Series
C} 47: 299--350.

\bibitem[\citeproctext]{ref-lindgren2011explicit}
Lindgren, Finn, H√•vard Rue, and Johan Lindstr√∂m. 2011. {``An Explicit
Link Between Gaussian Fields and Gaussian Markov Random Fields: The
Stochastic Partial Differential Equation Approach.''} \emph{Journal of
the Royal Statistical Society Series B: Statistical Methodology} 73 (4):
423--98.

\end{CSLReferences}
\end{frame}




\end{document}
